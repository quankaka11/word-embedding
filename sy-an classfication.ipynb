{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_sy,path_an):\n",
    "    synonym = pd.read_csv(path_sy, sep=' ', header=None)\n",
    "    antonym = pd.read_csv(path_an, sep=' ', header=None)\n",
    "\n",
    "    synonym['label'] = 1\n",
    "    antonym['label'] = 0\n",
    "\n",
    "    data = pd.concat([synonym, antonym], ignore_index=True)\n",
    "    data.columns = ['word1', 'word2', 'label']\n",
    "\n",
    "    missing_data = data[data['word2'].isna() | (data['word2'] == '')]\n",
    "    print(\"Dữ liệu miss được loại bỏ:\")\n",
    "    print(missing_data)\n",
    "\n",
    "    data = data[data['word2'].notna() & (data['word2'] != '')]\n",
    "    \n",
    "\n",
    "    data['pair'] = data['word1'] + ' ' + data['word2']\n",
    "    X = data['pair']\n",
    "    y = data['label']\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu miss được loại bỏ:\n",
      "           word1 word2  label\n",
      "562   bằng_chứng   NaN      1\n",
      "2941  dài_ngoằng   NaN      1\n",
      "3097    dầu_nhớt   NaN      1\n",
      "3195   diễn_dịch   NaN      1\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data('an-sy/Synonym_vietnamese.txt', 'an-sy/Antonym_vietnamese.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            a_dua a_tòng\n",
       "1           a_dua vào_hùa\n",
       "2          a_ma_tơ tài_tử\n",
       "3          a_tòng vào_hùa\n",
       "4               à_ơi ạ_ơi\n",
       "               ...       \n",
       "13557    bẩn_thỉu sạch_sẽ\n",
       "13558            bận rảnh\n",
       "13559       bận rảnh_rang\n",
       "13560        bận rảnh_rỗi\n",
       "13561             bận rỗi\n",
       "Name: pair, Length: 13558, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_vec, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "\n",
    "    print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print('Classification report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('Confusion matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "    return model, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8978613569321534\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.39      0.53       401\n",
      "           1       0.90      0.99      0.94      2311\n",
      "\n",
      "    accuracy                           0.90      2712\n",
      "   macro avg       0.87      0.69      0.74      2712\n",
      "weighted avg       0.89      0.90      0.88      2712\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 155  246]\n",
      " [  31 2280]]\n",
      "\n",
      "đi và đứng là từ đồng nghĩa\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = train_model(X, y)\n",
    "\n",
    "def predict(model, vectorizer, word1, word2):\n",
    "    pair = word1 + ' ' + word2\n",
    "    pair_vec = vectorizer.transform([pair])\n",
    "\n",
    "    pred = model.predict(pair_vec)[0]\n",
    "\n",
    "    if pred == 1:\n",
    "        return '{word1} và {word2} là từ đồng nghĩa'.format(word1=word1, word2=word2)\n",
    "    else:\n",
    "        return '{word1} và {word2} là từ trái nghĩa'.format(word1=word1, word2=word2)\n",
    "    \n",
    "print(predict(model, vectorizer, 'đi', 'đứng'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
